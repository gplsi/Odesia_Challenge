version: '3.4'
services:
  weaviate:
    image: semitechnologies/weaviate:1.20.5
    ports:
      - 8080:8080
    environment:
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'none'

  langchain-inference:
      build:
        context: .
      container_name: langchain_inference
      ports:
        - "8000:8000"
      depends_on:
        - weaviate
      deploy:
        resources:
          reservations:
            devices:
              - capabilities: ["gpu"]
      volumes:
        - ./:workspace/
      command: ["tail", "-f", "/dev/null"]